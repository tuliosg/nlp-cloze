{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f86f4fc",
   "metadata": {},
   "source": [
    "# **Organização dos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75dc540",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2260e0",
   "metadata": {},
   "source": [
    "### **Extração dos contextos e gabarito**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82595cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexto_gabarito(arquivo, titulo):\n",
    "    \n",
    "    with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "        dados_json = json.load(f)\n",
    "\n",
    "    texto_info = None\n",
    "    for item in dados_json:\n",
    "        if item.get(\"titulo\") == titulo:\n",
    "            texto_info = item\n",
    "            break\n",
    "    \n",
    "    if not texto_info:\n",
    "        return []\n",
    "\n",
    "    texto_completo = texto_info['texto']\n",
    "    respostas = texto_info['respostas']\n",
    "\n",
    "    frases_finais = []\n",
    "    indice_resposta = 0\n",
    "\n",
    "    frases = texto_completo.replace('\\n', ' ').split('.')\n",
    "\n",
    "    for frase in frases:\n",
    "        num_lacunas = frase.count('[LACUNA]')\n",
    "\n",
    "        if not num_lacunas:\n",
    "            continue\n",
    "\n",
    "        partes = frase.split('[LACUNA]')\n",
    "        \n",
    "        respostas_locais = respostas[indice_resposta : indice_resposta + num_lacunas]\n",
    "\n",
    "        for i in range(num_lacunas):\n",
    "            preenchimentos = list(respostas_locais)\n",
    "            preenchimentos[i] = '[LACUNA]'\n",
    "            \n",
    "            nova_frase = \"\".join(p + f for p, f in zip(partes, preenchimentos)) + partes[-1]\n",
    "            \n",
    "            frases_finais.append(nova_frase.strip())\n",
    "        \n",
    "        indice_resposta += num_lacunas\n",
    "\n",
    "    return frases_finais, respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83417e",
   "metadata": {},
   "source": [
    "## **Mapeamento das correções e organização dos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_CORRECAO = {\n",
    "    'mesma classe e campo semântico diferente': 'classe_correta',\n",
    "    'mesma classe e mesmo campo semântico': 'aceitavel',\n",
    "    '-': 'incorreta'\n",
    "}\n",
    "\n",
    "dir_dados = '../data/raw'\n",
    "dir_textos = '../data/textos.json'\n",
    "dir_saida = '../data/processed/[human-eval]dados_teste-cloze.csv'\n",
    "\n",
    "arquivos = os.listdir(dir_dados)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    caminho_completo_csv = os.path.join(dir_dados, arquivo)\n",
    "\n",
    "    df_raw = pd.read_csv(caminho_completo_csv)\n",
    "\n",
    "    titulo_texto = df_raw[\"texto\"].iloc[0]\n",
    "    \n",
    "    contextos_texto, gabarito_texto = get_contexto_gabarito(dir_textos, titulo_texto)\n",
    "\n",
    "    for _, row in df_raw.iterrows():\n",
    "        for i in range(1, len(gabarito_texto)+1):\n",
    "            lacuna_col = f'lacuna_{i}'\n",
    "            class_col = f'classificacao_{i}'\n",
    "            corr_col = f'correcao_{i}'\n",
    "            \n",
    "            if lacuna_col in row and pd.notna(row[lacuna_col]):\n",
    "                \n",
    "                correcao_original = row.get(corr_col, '-')\n",
    "                correcao_mapeada = MAP_CORRECAO.get(correcao_original, 'incorreta')\n",
    "                \n",
    "                lacuna_aluno = str(row[lacuna_col]).strip().lower()\n",
    "                resposta_correta = str(gabarito_texto[i-1]).strip().lower()\n",
    "                \n",
    "                if lacuna_aluno == resposta_correta:\n",
    "                    correcao_mapeada = 'exata'\n",
    "\n",
    "                all_data.append({\n",
    "                    'contexto': contextos_texto[i-1],\n",
    "                    'lacuna': row[lacuna_col],\n",
    "                    'gabarito': gabarito_texto[i-1],\n",
    "                    'classificacao': row.get(class_col, \"\"),\n",
    "                    'correcao': correcao_mapeada\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cloze = pd.DataFrame(all_data)\n",
    "\n",
    "df_cloze.to_csv(dir_saida, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
